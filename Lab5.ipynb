{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlphonsaJo/Lab_1_MachineLearning/blob/main/Lab5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5001140-4523-47c0-b421-8962ac3311e2",
      "metadata": {
        "id": "f5001140-4523-47c0-b421-8962ac3311e2",
        "outputId": "e942135f-cef4-41bf-c7dd-b8c9b7913701"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Loss: 0.4161388411334396\n",
            "Epoch 100, Loss: 0.12069006865468915\n",
            "Epoch 200, Loss: 0.0792668659775606\n",
            "Epoch 300, Loss: 0.06074600493288359\n",
            "Epoch 400, Loss: 0.04975000538380399\n",
            "Epoch 500, Loss: 0.04231400066933356\n",
            "Epoch 600, Loss: 0.0368943904403494\n",
            "Epoch 700, Loss: 0.03274597002427891\n",
            "Epoch 800, Loss: 0.029457943434548807\n",
            "Epoch 900, Loss: 0.026782576791196548\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Create a DataFrame from the provided data\n",
        "data = {\n",
        "    'Customer': ['C_1', 'C_2', 'C_3', 'C_4', 'C_5', 'C_6', 'C_7', 'C_8', 'C_9', 'C_10'],\n",
        "    'Candies (#)': [20, 16, 27, 19, 24, 22, 15, 18, 21, 16],\n",
        "    'Mangoes (kg)': [6, 3, 6, 1, 4, 1, 4, 4, 1, 2],\n",
        "    'Milk Packets (#)': [2, 6, 2, 2, 2, 5, 2, 2, 4, 4],\n",
        "    'Payment (Rs)': [386, 289, 393, 110, 280, 167, 271, 274, 148, 198],\n",
        "    'High Value (Tx)': ['Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'No', 'No']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Step 2: Data Preprocessing\n",
        "# Encode the target variable 'High Value (Tx)' to 1 for 'Yes' and 0 for 'No'\n",
        "df['High Value (Tx)'] = df['High Value (Tx)'].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "# Normalize the numerical features (Candies (#), Mangoes (kg), Milk Packets (#), Payment (Rs))\n",
        "numerical_features = ['Candies (#)', 'Mangoes (kg)', 'Milk Packets (#)', 'Payment (Rs)']\n",
        "df[numerical_features] = (df[numerical_features] - df[numerical_features].mean()) / df[numerical_features].std()\n",
        "\n",
        "# Step 3: Initialize Weights and Bias\n",
        "np.random.seed(0)\n",
        "num_features = len(numerical_features)\n",
        "weights = np.random.rand(num_features)\n",
        "bias = np.random.rand()\n",
        "\n",
        "# Step 4: Define the Sigmoid Activation Function\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Step 5: Define the Perceptron Model\n",
        "def perceptron(input_features, weights, bias):\n",
        "    return sigmoid(np.dot(input_features, weights) + bias)\n",
        "\n",
        "# Step 6: Define the Binary Cross-Entropy Loss Function\n",
        "def loss(y_true, y_pred):\n",
        "    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
        "\n",
        "# Step 7: Training the Perceptron\n",
        "learning_rate = 0.1\n",
        "num_epochs = 1000\n",
        "\n",
        "X = df[numerical_features].values\n",
        "y = df['High Value (Tx)'].values\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass\n",
        "    predictions = perceptron(X, weights, bias)\n",
        "\n",
        "    # Calculate the loss\n",
        "    error = loss(y, predictions)\n",
        "\n",
        "    # Gradient descent to update weights and bias\n",
        "    gradient = np.dot(X.T, (predictions - y)) / len(y)\n",
        "    weights -= learning_rate * gradient\n",
        "    bias -= learning_rate * np.mean(predictions - y)\n",
        "\n",
        "    # Print the loss at each epoch (optional)\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {error}\")\n",
        "\n",
        "# Step 8: Make Predictions (using the trained perceptron)\n",
        "# You can use the trained perceptron to make predictions on new data or evaluate on the existing data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2002c13-422d-49fc-8cf6-f0a3fb70d80a",
      "metadata": {
        "id": "f2002c13-422d-49fc-8cf6-f0a3fb70d80a",
        "outputId": "0f8f2c9a-9db0-4aa9-efcd-92da6cbbd070"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Loss: 0.4607266308088649\n",
            "Epoch 100, Loss: 0.11632762688739122\n",
            "Epoch 200, Loss: 0.0757555622362701\n",
            "Epoch 300, Loss: 0.05825083665027024\n",
            "Epoch 400, Loss: 0.047914728156162156\n",
            "Epoch 500, Loss: 0.040913784043544114\n",
            "Epoch 600, Loss: 0.03579332991505704\n",
            "Epoch 700, Loss: 0.031858655276917926\n",
            "Epoch 800, Loss: 0.02872834590793631\n",
            "Epoch 900, Loss: 0.02617252470637011\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "#each input feature is assigned a weight.\n",
        "\n",
        "\n",
        "\n",
        "class Perceptron:\n",
        "    def __init__(self, num_features):\n",
        "        self.weights = np.random.rand(num_features)\n",
        "        self.bias = np.random.rand()\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def predict(self, input_features):\n",
        "        return self.sigmoid(np.dot(input_features, self.weights) + self.bias)\n",
        "\n",
        "    def loss(self, y_true, y_pred):\n",
        "        return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
        "\n",
        "    def train(self, X, y, learning_rate, num_epochs):\n",
        "        for epoch in range(num_epochs):\n",
        "            # Forward pass\n",
        "            predictions = self.predict(X)\n",
        "\n",
        "            # Calculate the loss\n",
        "            error = self.loss(y, predictions)\n",
        "\n",
        "            # Gradient descent to update weights and bias\n",
        "            gradient = np.dot(X.T, (predictions - y)) / len(y)\n",
        "            self.weights -= learning_rate * gradient\n",
        "            self.bias -= learning_rate * np.mean(predictions - y)\n",
        "\n",
        "            # Print the loss at each epoch (optional)\n",
        "            if epoch % 100 == 0:\n",
        "                print(f\"Epoch {epoch}, Loss: {error}\")\n",
        "\n",
        "# Example usage:\n",
        "numerical_features = ['Candies (#)', 'Mangoes (kg)', 'Milk Packets (#)', 'Payment (Rs)']\n",
        "X = df[numerical_features].values\n",
        "y = df['High Value (Tx)'].values\n",
        "\n",
        "perceptron_model = Perceptron(num_features=len(numerical_features))\n",
        "perceptron_model.train(X, y, learning_rate=0.1, num_epochs=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0a3433d-e172-4263-93fa-8b046ca2c5fc",
      "metadata": {
        "id": "c0a3433d-e172-4263-93fa-8b046ca2c5fc",
        "outputId": "40dc0e93-a6a0-4c1d-ee23-03086a96ad6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matrix Pseudo-Inverse Predictions: [1. 0.]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Sample data (replace with your dataset)\n",
        "X = np.array([[20, 6, 2, 386],\n",
        "              [16, 3, 6, 289],\n",
        "              [27, 6, 2, 393],\n",
        "              [19, 1, 2, 110],\n",
        "              [24, 4, 2, 280],\n",
        "              [22, 1, 5, 167],\n",
        "              [15, 4, 2, 271],\n",
        "              [18, 4, 2, 274],\n",
        "              [21, 1, 4, 148],\n",
        "              [16, 2, 4, 198]])\n",
        "\n",
        "y = np.array([1, 1, 1, 0, 1, 0, 1, 1, 0, 0])\n",
        "\n",
        "# Adding a bias term to the input features\n",
        "X = np.column_stack((X, np.ones(len(X))))\n",
        "\n",
        "# Calculate the weights using the matrix pseudo-inverse method\n",
        "weights = np.dot(np.linalg.pinv(X), y)\n",
        "\n",
        "# Make predictions using the calculated weights\n",
        "def predict(input_features):\n",
        "    input_features = np.column_stack((input_features, np.ones(len(input_features))))\n",
        "    return np.round(np.dot(input_features, weights))\n",
        "\n",
        "# Test the model with new data (replace with your test data)\n",
        "new_data = np.array([[25, 5, 2, 350],\n",
        "                     [18, 2, 3, 220]])\n",
        "\n",
        "predictions_matrix_pseudo_inverse = predict(new_data)\n",
        "print(\"Matrix Pseudo-Inverse Predictions:\", predictions_matrix_pseudo_inverse)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc8911f1-58f4-48ef-951b-f2f4aae82f59",
      "metadata": {
        "id": "cc8911f1-58f4-48ef-951b-f2f4aae82f59"
      },
      "outputs": [],
      "source": [
        "#A7. Develop the below Neural Network. Use learning rate (Î±) = 0.05 with a Sigmoid activation\n",
        "function. Learn the weights of the network using back-propagation algorithm to implement above\n",
        "provided AND gate logic.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Define the Sigmoid activation function\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Initialize weights and bias randomly\n",
        "np.random.seed(0)  # For reproducibility\n",
        "weights = np.random.randn(2)\n",
        "bias = np.random.randn()\n",
        "\n",
        "# Define the learning rate\n",
        "learning_rate = 0.05\n",
        "\n",
        "# Define the training data for the AND gate\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = np.array([0, 0, 0, 1])\n",
        "\n",
        "# Training the network\n",
        "epochs = 10000\n",
        "for epoch in range(epochs):\n",
        "    # Forward pass\n",
        "    output = sigmoid(np.dot(X, weights) + bias)\n",
        "\n",
        "    # Compute Mean Squared Error (MSE) loss\n",
        "    loss = np.mean((output - y) ** 2)\n",
        "\n",
        "    # Backpropagation\n",
        "    gradient = 2 * (output - y) * output * (1 - output)\n",
        "    weights -= learning_rate * np.dot(X.T, gradient)\n",
        "    bias -= learning_rate * np.sum(gradient)\n",
        "\n",
        "    # Print loss for monitoring (optional)\n",
        "    if epoch % 1000 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss}\")\n",
        "\n",
        "# Testing the network\n",
        "test_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "predictions = np.round(sigmoid(np.dot(test_data, weights) + bias))\n",
        "\n",
        "# Display the predictions for the AND gate logic\n",
        "print(\"Predictions for AND gate:\")\n",
        "for i in range(len(test_data)):\n",
        "    print(f\"Input: {test_data[i]}, Output: {int(predictions[i])}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}